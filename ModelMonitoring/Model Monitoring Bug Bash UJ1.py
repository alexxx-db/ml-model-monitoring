# Databricks notebook source
# MAGIC %md 
# MAGIC 
# MAGIC # Model Monitoring Bug Bash UJ1
# MAGIC 
# MAGIC Please make a copy of this notebook before use.

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC 
# MAGIC Useful links:
# MAGIC  - [Bug Bash Doc](http://go/modmon/bugbash)
# MAGIC  - [Quickstart Notebook](https://e2-dogfood.staging.cloud.databricks.com/?o=6051921418418893#notebook/2390739687257529/command/2133117006775689)
# MAGIC  - [API Reference](https://docs.google.com/document/d/1L_fqZzz9ABx2E10NMW8Pg0EdtKpxJxAwJNJiVCaCgCs/edit#heading=h.x3x9cjfy4srj)
# MAGIC  - [User Guide](https://docs.google.com/document/d/1pWUEPY7vF80BSrQp_cqGjowo7Zn91_VvuoZ6J-ZeUKk/edit#heading=h.pc8x54hv4i93)

# COMMAND ----------

# Install model monitoring client library. Eventually this will be included in MLR
%pip install "https://ml-team-public-read.s3.amazonaws.com/wheels/model-monitoring/e7394149-4c48-42a3-94af-11cee8964415/databricks_model_monitoring-0.0.0.dev0-py3-none-any.whl"

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ## Create the monitor
# MAGIC 
# MAGIC We have registered a classification model [mm_bug_bash](https://e2-dogfood.staging.cloud.databricks.com/?o=6051921418418893#mlflow/models/mm_bug_bash) for you. 
# MAGIC 
# MAGIC The model is trained with Census Income csv dataset `/dbfs/databricks-datasets/adult/adult.data` and the ground-truth column is `income`. If you want to explore the dataset, you can use following code snippet to load it:
# MAGIC ```
# MAGIC import pandas as pd
# MAGIC cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',
# MAGIC         'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',
# MAGIC         'hours-per-week', 'native-country', 'income']
# MAGIC pdf = pd.read_csv(
# MAGIC   "/dbfs/databricks-datasets/adult/adult.data",
# MAGIC   names=cols,
# MAGIC   skipinitialspace=True,
# MAGIC )
# MAGIC df = spark.createDataFrame(pdf)
# MAGIC ```

# COMMAND ----------

# We recommend to use your name in the monitor name to avoid the conflict with other people.
monitor_name = "{your_name}_monitor"
model_name = "mm_bug_bash"

assert(monitor_name != "{your_name}_monitor")

# COMMAND ----------

from pyspark.sql import types as T
import databricks.model_monitoring as mm

mm_info = mm.create_monitor(
  # UJ: Fill the parameters to create the monitor.
)

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ## Inspect the monitor

# COMMAND ----------

mm.get_monitor_info(
  # UJ: Fill the parameters to inspect the monitor by API.
)

# UJ: Inspect the monitor by the monitor tab in the model registry page.
# UJ: inspecting each artifact (e.g. table, pipeline, dashboard) generated by the library.

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ## Delete the monitor

# COMMAND ----------

mm.delete_monitor(
  # UJ: Fill the right parameters to delete the monitor.
)
